\documentclass[aip,jcp,a4paper,reprint,onecolumn]{revtex4-1}

\usepackage[fleqn]{amsmath}
\usepackage{amssymb}
\usepackage[dvips]{graphicx}
\usepackage{color}
\usepackage{tabularx}
\usepackage{algorithm}
\usepackage{algorithmic}

\makeatletter
\makeatother

\newcommand{\recheck}[1]{{\color{red} #1}}
\newcommand{\redc}[1]{{\color{red} #1}}
\newcommand{\bluec}[1]{{\color{blue} #1}}
\newcommand{\vect}[1]{\textbf{\textit{#1}}}
\newcommand{\dd}{\textsf{d}}
\newcommand{\inv}{\textrm{inv}}
\newcommand{\hard}{\textrm{h}}
\newcommand{\soft}{\textrm{s}}
\newcommand{\vdw}{\textrm{vdw}}
\newcommand{\ele}{\textrm{ele}}
\newcommand{\dir}{\textrm{dir}}
\newcommand{\rec}{\textrm{rec}}
\newcommand{\corr}{\textrm{corr}}

\newcommand{\mh}{\mathcal H}
\newcommand{\eps}{\varepsilon}
\newcommand{\ml}{\mathcal L}
\newcommand{\me}{\mathcal E}
\newcommand{\mt}{\mathcal T}
\newcommand{\mo}{\mathcal O}
\newcommand{\mi}{\mathcal I}
\newcommand{\mc}{\mathcal C}
\newcommand{\proj}{\mathit\Pi}
\newcommand{\fwg}{{\mathcal A}}
\newcommand{\bwg}{{\mathcal B}}
\newcommand{\bsigma}{\boldsymbol\sigma}
\newcommand{\pathmeas}{d\mathcal P}
\newcommand{\dist}{\textrm{dist}}


\begin{document}


\title{Report: Important sampling by the cross-entropy method}
\author{Han Wang}
\affiliation{Institute for Mathematics, Freie Universit\"at Berlin, Germany}
% \author{Christof Sch\"utte}
% \affiliation{Institute for Mathematics, Freie Universit\"at Berlin, Germany}
% \affiliation{Zuse Institute Berlin (ZIB), Germany}
% \affiliation{Institute for Mathematics, Freie Universit\"at Berlin, Germany}

\date{\today}

\begin{abstract}
\end{abstract}

\maketitle

\section{Theory}
We study the following stochastic process:
\begin{align}\label{eqn:sde}
  dx_t = b(x_t) dt + \sigma dw_t,
\end{align}
and are interested in the observable defined by
\begin{align}
  O = \mathbb E(F[x_t]) = \int F[x_t] \pathmeas[x_t],
\end{align}
where $\pathmeas[x_t]$ defines the probability measure of the
trajectories generated by process~\eqref{eqn:sde}.  We want to reduce
the variance of calculating observable $O$ by applying control
$c(x_t)$ to the system, i.e.
\begin{align}
  dx_t = b(x_t) dt + c(x_t) dt + \sigma dw_t,  
\end{align}
Now the probability measure of the trajectories is denoted by
$\pathmeas_c[x_t]$. The observable is calculated by
\begin{align}
  O = \int F[x_t] \frac{\pathmeas[x_t]}{\pathmeas_c[x_t]} \pathmeas_c[x_t]
\end{align}
By the Girsanov transformation, we have
\begin{align}
  \frac{\pathmeas[x_t]}{\pathmeas_c[x_t]} = 
  \exp \Big\{ - \frac 1\sigma \int_0^t c(x_s) dw_s - \frac1{2\sigma^2} \int_0^t c^2(x_s) ds\Big\}
\end{align}\\

\noindent
The optimal control that minimized the variance of calculting the observable is reached when
\begin{align}\label{eqn:min-cond-1}
  \pathmeas_c^\ast[x_t] =\textrm{C} F[x_t] \pathmeas[x_t]
\end{align}
The constant \textrm{C} is determined with the nomorlization relation.
The cross-entropy, as a measure of the distance between two
probability measures, is defined by
\begin{align}
  \dist(\pathmeas_1, \pathmeas_2)
  = \mathbb E_1 \Big[\log \Big(\frac{\pathmeas_1}{\pathmeas_2}\Big)\Big]
  = \int \log \Big(\frac{\pathmeas_1}{\pathmeas_2}\Big)\, \pathmeas_1
\end{align}
In order to calculate the optimal control $\pathmeas_c^\ast$, we
minmize the distance between the measure $\pathmeas_c$~and the
R.H.S.~of Eq.~\eqref{eqn:min-cond-1}, and savely neglecting the
constant in the equation:
\begin{align}
  \min_c \int  \log \Big( \frac{F[x_t]\pathmeas[x_t]}{\pathmeas_c[x_t]} \Big) F[x_t]\pathmeas[x_t],
\end{align}
which is equivalent to the problem
\begin{align}\label{eqn:max-1}
  \max_c \int \log \Big(\frac{\pathmeas_c[x_t]}{\pathmeas[x_t]} \Big) F[x_t]\pathmeas[x_t].
\end{align}
Computationally, we provide an intial guess for the control $c_0$, then we can change Eq.~\eqref{eqn:max-1} to
\begin{align}
  \max_c \int
  \log \Big(\frac{\pathmeas_c[x_t]}{\pathmeas_{c_0}[x_t]} \Big)
  F[x_t]
  \frac{\pathmeas[x_t]}{\pathmeas_{c_0}[x_t]}
  \,\pathmeas_{c_0}[x_t]
\end{align}
A step with the Girsanov transformation
\begin{align}
  \max_c \int
  \Big[\, \frac1\sigma\int_0^t\tilde c(x_s) dw_s - \frac 1{2\sigma^2} \int_0^t\tilde c^2(x_s) ds \,\Big]
  \,F[x_t]\,
  \exp
  \Big\{ -\frac1\sigma\int_0^t c_0(x_s) dw_s - \frac 1{2\sigma^2} \int_0^t c_0^2(x_s) ds \Big \}
  \,\pathmeas_{c_0}[x_t].
\end{align}
where we denote the increment of the control by
\begin{align}
  \tilde c = c - c_0.
\end{align}
We expand the control with respect to a set of base functions $\{\varphi_i\}$:
\begin{align}
  c = \sum_{i=0}^N w_i\varphi_i, \quad c_0 = \sum_{i=0}^N w_{0,i}\varphi_i, \quad \tilde c = \sum_{i=0}^N \tilde w_i\varphi_i,
\end{align}
We then have the optimization problem
\begin{align}
  \max \int F[x_t]
  \Big ( \sum_i \tilde w_i g_i - \frac12\sum_{ij} \tilde w_i\tilde w_j h_{ij} \Big)
  \exp \Big\{
  - \sum_i w_{0,i} g_i - \frac 12 \sum_{ij} h_{ij} w_{0,i}    w_{0,j} \Big\}
  \,\pathmeas_{c_0}[x_t]
\end{align}
with
\begin{align}\label{eqn:gi}
  g_i[x_t] & = \frac 1\sigma\int_0^t \varphi_i(x_s) dw_s \\\label{eqn:hij}
  h_{ij}[x_t] & = \frac1{\sigma^2} \int_0^t \varphi_i(x_s)  \varphi_j(x_s) ds
\end{align}
Now define
\begin{align}
  b_i & = \int F[x_t]\, g_{i}[x_t] \exp \Big\{
  - \sum_i w_{0,i} g_i - \frac 12 \sum_{ij} h_{ij} w_{0,i}    w_{0,j} \Big\}
  \,\pathmeas_{c_0}[x_t]\\
  A_{ij} & = \int F[x_t]\, h_{ij}[x_t] \exp \Big\{
  - \sum_i w_{0,i} g_i - \frac 12 \sum_{ij} h_{ij} w_{0,i}    w_{0,j} \Big\}
  \,\pathmeas_{c_0}[x_t]
\end{align}
Then the optimization problem is
\begin{align}
  \max_{\tilde w } -\frac 12 \tilde w^T A w + b^T \tilde w
\end{align}
To find the optimal control, we need only to solve the linear equation
\begin{align}
  A\tilde w = b, \quad \textrm{or}\quad A w = A w_0 + b
\end{align}
In practice, due to the statistical uncertainty, this equation may not
be solve exactly, so we need a iterative process:
\begin{align}
  w_{i+1} = w_i + A^{-1}b
\end{align}
After we have got the converged control $w_i^\ast$,
i.e.~the optimal one, we have
the observable calculated by
\begin{align}\label{eqn:fin-obs}
  O = \int F[x_t]\,
  \exp\Big\{
  -\sum_iw^\ast_i g_i -\frac12\sum_{ij}w^\ast_iw^\ast_jh_{ij}
  \Big\}\,
  \pathmeas_{c^\ast}[x_t]
\end{align}

\subsection{Variance reduction}

The calculation of the observable, i.e.~Eq.~\eqref{eqn:fin-obs} can be
optimized by a variance reduction technique, which is computationally
very cheap, and can increase the accuracy significantly. We assume
that the noise $dw_t$ can be divided into two parts,
\begin{align}
  dw_s = f(dw_s) + [\,dw_s - f(dw_s)\,].
\end{align}
The first part is statistically independent with the functional
$F[x_t]$ and the second part. For simplicity, we assume this splitting
is the same for all the base functions $\varphi_i$. It can be, take the
butane system for example, the translational component of $dw_s$, then
it is independent with $F[x_t]$, if the latter is the dihedral angle
of the butane.  We then have the splitting of $g_i$:
\begin{align}
  g_i[x_t]
  = g_i^i[x_t] + g_i^d[x_t]
  = \frac1\sigma\int_0^t\varphi_i(x_s) f(dw_s)
  + \frac1\sigma\int_0^t\varphi_i(x_s) [1 - f(dw_s)]
\end{align}
We want to prove that
\begin{align}\label{eqn:o-approx}
  O \approx \int F[x_t]
  \exp\Big\{
  -\sum_iw^\ast_i g^d_i -\frac12\sum_{ij}w^\ast_iw^\ast_jh_{ij}
  \Big\}\,
  \pathmeas_{c^\ast}[x_t]    
\end{align}
We start from Eq.~\eqref{eqn:fin-obs}:
\begin{align}
  O = \int F[x_t]
  \exp\Big\{
  -\sum_i w^\ast_ig^i_i
  -\sum_iw^\ast_i g^d_i -\frac12\sum_{ij}w^\ast_iw^\ast_jh_{ij}
  \Big\}\,
  \pathmeas_{c^\ast}[x_t]  
\end{align}
If we further assume that $w_i^\ast$ is small, the Taylor expansion to
the first order gives
\begin{align}
  O \approx \int F[x_t]
  \Big( 1 - \sum_i w_i^\ast g_i^i   -\sum_iw^\ast_i g^d_i\Big)
  \pathmeas_{c^\ast}[x_t]    
\end{align}
Take the term with $g_i^i$, it gives
\begin{align}
  w_i^\ast \frac1\sigma
  \int F[x_t] 
  \Big[ \int_0^t\varphi_i(x_s)f(dw_s)
  \Big]
  \pathmeas_{c^\ast}[x_t].
\end{align}
Due to the statistical independency, it is equal to
\begin{align}\label{eqn:tmp28}
  w_i^\ast \frac1\sigma
  \int
    \Big[ \int_0^t\varphi_i(x_s)f(dw_s)
  \Big]
  \pathmeas_{c^\ast}[x_t]
  \cdot
  \int F[x_t] 
  \pathmeas_{c^\ast}[x_t] = 0, 
\end{align}
because the first expectation value in Eq.~\eqref{eqn:tmp28} is equal to 0.
Therefore, Eq.~\eqref{eqn:o-approx} holds.
% If we further assume that $w_i^\ast g_i^i$ is small, the Taylor expansion of
% the first exponent gives
% \begin{align}
%   O \approx \int F[x_t]
%   \Big( 1 - \sum_i w_i^\ast g_i^i \Big)
%   \exp\Big\{
%   -\sum_iw^\ast_i g^d_i -\frac12\sum_{ij}w^\ast_iw^\ast_jh_{ij}
%   \Big\}\,
%   \pathmeas_{c^\ast}[x_t]    
% \end{align}
% Take one of the term in the first sum for example
% \begin{align}
%   w_i^\ast \frac1\sigma
%   \int F[x_t] 
%   \Big[ \int_0^t\varphi_i(x_s)f(dw_s)
%   \Big]
%   \exp\Big\{
%   -\sum_iw^\ast_i g^d_i -\frac12\sum_{ij}w^\ast_iw^\ast_jh_{ij}
%   \Big\}\,
%   \pathmeas_{c^\ast}[x_t],
% \end{align}
% which is equal to
% \begin{align}\label{eqn:tmp28}
%   w_i^\ast \frac1\sigma
%   \int
%     \Big[ \int_0^t\varphi_i(x_s)f(dw_s)
%   \Big]
%   \pathmeas_{c^\ast}[x_t]
%   \cdot
%   \int F[x_t] 
%   \exp\Big\{
%   -\sum_iw^\ast_i g^d_i -\frac12\sum_{ij}w^\ast_iw^\ast_jh_{ij}
%   \Big\}\,
%   \pathmeas_{c^\ast}[x_t] = 0, 
% \end{align}
% because the first expectation value in Eq.~\eqref{eqn:tmp28} is equal to 0.
% Therefore, Eq.~\eqref{eqn:o-approx} holds.

\section{Results}
The numerical results are summarized in the tables.
\begin{table}[th]
  \centering
  \caption{In solvent, variance reduction}
  \begin{tabular*}{0.8\textwidth}{@{\extracolsep{\fill}}lcccrr}
    \hline\hline
    $b$ & $P (\tau \leq b)$ & error & Var & accel. & Traj. Usage \\\hline
    0.1 & $4.34\times 10^{-5}$ & $1.16\times 10^{-5}$ & $2.31\times10^{-6}$ &18.8 & 0.7\%\\
    0.2 & $9.03\times 10^{-4}$ & $0.77\times 10^{-4}$ & $1.19\times10^{-4}$ & 7.6 &10.0\%\\
    0.5 & $6.96\times 10^{-3}$ & $0.34\times 10^{-3}$ & $2.21\times10^{-3}$ & 3.1 &11.9\%\\
    1.0 & $1.68\times 10^{-2}$ & $0.06\times 10^{-2}$ & $6.30\times10^{-3}$ & 2.7 &13.4\%\\
    \hline\hline
  \end{tabular*}
  \caption{In solvent, brute force}
  \begin{tabular*}{0.8\textwidth}{@{\extracolsep{\fill}}lcccrr}
    \hline\hline
    $b$ & $P (\tau \leq b)$ & error & Var & accel. & Traj. Usage \\\hline
    0.2 & $7.46\times 10^{-4}$ & $2.36\times 10^{-4}$ & $7.46\times10^{-4}$ & 1.0 & 0.1\%\\
    0.5 & $6.94\times 10^{-3}$ & $0.72\times 10^{-3}$ & $6.89\times10^{-3}$ & 1.0 & 0.7\%\\
    1.0 & $1.61\times 10^{-2}$ & $0.11\times 10^{-2}$ & $1.59\times10^{-3}$ & 1.0 & 1.6\%\\
    \hline\hline
  \end{tabular*}
\end{table}

\begin{table}[th]
  \centering
  \caption{Free molecule}
  \begin{tabular*}{0.8\textwidth}{@{\extracolsep{\fill}}lcccrr}
    \hline\hline
    $b$ & $P (\tau \leq b)$ & error & Var & accel. & Traj. Usage \\\hline
    0.1 & $6.38\times 10^{-5}$ & $1.75\times 10^{-5}$ & $1.23\times10^{-5}$ & 5.2 & 0.5\%\\
    0.2 & $1.59\times 10^{-3}$ & $0.17\times 10^{-3}$ & $4.79\times10^{-4}$ & 3.3 & 9.3\%\\
    0.5 & $8.27\times 10^{-3}$ & $0.49\times 10^{-3}$ & $4.75\times10^{-3}$ & 1.7 &11.8\%\\
    1.0 & $2.21\times 10^{-2}$ & $0.09\times 10^{-2}$ & $1.49\times10^{-2}$ & 1.5 &14.3\%\\
    \hline\hline
  \end{tabular*}
  \label{tab:tmp1}
  \caption{Free molecule after variance reduction}
  \begin{tabular*}{0.8\textwidth}{@{\extracolsep{\fill}}lcccrr}
    \hline\hline
    $b$ & $P (\tau \leq b)$ & error & Var & accel. & Traj. Usage \\\hline
    0.1 & $5.76\times 10^{-5}$ & $0.70\times 10^{-5}$ & $3.73\times10^{-6}$ &15.6 & 1.2\%\\
    0.2 & $1.35\times 10^{-3}$ & $0.09\times 10^{-3}$ & $1.55\times10^{-4}$ & 8.7 &17.1\%\\
    0.5 & $9.32\times 10^{-3}$ & $0.40\times 10^{-3}$ & $3.27\times10^{-3}$ & 2.9 &16.9\%\\
    1.0 & $2.19\times 10^{-2}$ & $0.07\times 10^{-2}$ & $1.03\times10^{-2}$ & 2.1 &18.5\%\\
    \hline\hline
  \end{tabular*}
  \caption{Two points fixed molecule}
  \begin{tabular*}{0.8\textwidth}{@{\extracolsep{\fill}}lcccrr}
    \hline\hline
    $b$ & $P (\tau \leq b)$ & error & Var & accel. & Traj. Usage \\\hline
    0.1 & $2.23\times 10^{-6}$ & $1.49\times 10^{-6}$ & $1.26\times10^{-7}$ & 17.7 & 0.1\%\\
    0.2 & $3.27\times 10^{-4}$ & $0.27\times 10^{-4}$ & $2.42\times10^{-5}$ & 13.5  & 43.0\%\\
    0.5 & $4.58\times 10^{-3}$ & $0.18\times 10^{-4}$ & $6.55\times10^{-4}$ & 7.0 & 68.6\%\\
    1.0 & $1.21\times 10^{-2}$ & $0.07\times 10^{-2}$ & $2.19\times10^{-3}$ & 5.5  & 47.5\%\\
    \hline\hline
  \end{tabular*}
  \caption{Three points fixed molecule}
  \begin{tabular*}{0.8\textwidth}{@{\extracolsep{\fill}}lcccrr}
    \hline\hline
    $b$ & $P (\tau \leq b)$ & error & Var & accel. & Traj. Usage \\\hline
    % 0.1 & $2.23\times 10^{-6}$ & $1.49\times 10^{-6}$ & $1.26\times10^{-7}$ & 17.7 & 0.1\%\\
    0.2 & $5.60\times 10^{-5}$ & $0.35\times 10^{-5}$ & $2.41\times10^{-7}$ & 231.4  & 44.8\%\\
    0.5 & $3.42\times 10^{-3}$ & $0.07\times 10^{-3}$ & $6.60\times10^{-5}$ & 49.3 & 74.0\%\\
    1.0 & $8.72\times 10^{-3}$ & $0.29\times 10^{-3}$ & $1.73\times10^{-3}$ & 5.0  & 82.2\%\\
    \hline\hline
  \end{tabular*}
\end{table}





\newpage
\section*{References}
\bibliography{ref}{}
\bibliographystyle{unsrt}




\end{document}
